{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# install fastkaggle if not available\n",
    "try: import fastkaggle\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -Uq fastkaggle\n",
    "\n",
    "from fastkaggle import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Iterate Like a Grandmaster](https://www.kaggle.com/code/jhoward/iterate-like-a-grandmaster) I explained that when working on a Kaggle project:\n",
    "\n",
    "> ...the focus generally should be two things:\n",
    "> \n",
    "> 1. Creating an effective validation set\n",
    "> 2. Iterating rapidly to find changes which improve results on the validation set.\n",
    "\n",
    "Here I'm going to go further, showing the process I used to tackle the [Paddy Doctor](https://www.kaggle.com/competitions/paddy-disease-classification) competition, leading to four submissions in a row which all were (at the time of submission) in 1st place, each one more accurate than the last. You might be surprised to discover that the process of doing this was nearly entirely mechanistic and didn't involve any consideration of the actual data or evaluation details at all.\n",
    "\n",
    "This notebook is the first in a series showing every step of the process. At the end of this notebook we'll have a basic submission; by the end of the series you'll see how I got to the top of the table!:\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/346999/174389920-60d67ead-0f36-41d0-9649-e23b08720c8a.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a special extra, I'm also opening up early a selection of \"walkthru\" videos that we've been preparing for the new upcoming fast.ai course. Each day I do a walkthru with fast.ai fellows and registered students, and we record those sessions. They'll all be released at the same time as the next course (probably August 2022), but I'm releasing the ones covering this competition right now! Here they are:\n",
    "\n",
    "- [Walkthru 8](https://www.youtube.com/watch?v=-Scs4gbwWXg)\n",
    "- [Walkthru 9](https://www.youtube.com/watch?v=EK5wJRzffas)\n",
    "- [Walkthru 10](https://youtu.be/zhBRynq9Yvo)\n",
    "- [Walkthru 11](https://youtu.be/j-zMF2VirA8)\n",
    "- [Walkthru 12](https://youtu.be/GuCkpjXHdTc)\n",
    "- [Walkthru 13](https://youtu.be/INrkhUGCXHg)\n",
    "\n",
    "When you're done with this notebook, take a look at [part 2 of the series](https://www.kaggle.com/code/jhoward/small-models-road-to-the-top-part-2/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll get the data. I've just created a new library called [fastkaggle](https://fastai.github.io/fastkaggle/) which has a few handy features, including getting the data for a competition correctly regardless of whether we're running on Kaggle or elsewhere. Note you'll need to first accept the competition rules and join the competition, and you'll need your kaggle API key file `kaggle.json` downloaded if you're running this somewhere other than on Kaggle. `setup_comp` is the function we use in `fastkaggle` to grab the data, and install or upgrade our needed python modules when we're running on Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading paddy-disease-classification.zip to /Volumes/THALURU/DS/FastAI/chapter-6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1.02G/1.02G [00:41<00:00, 26.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "comp = 'paddy-disease-classification'\n",
    "\n",
    "path = setup_comp(comp, install='fastai \"timm>=0.6.2.dev0\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=Path('paddy-disease-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import the stuff we'll need from fastai, set a seed (for reproducibility -- just for the purposes of making this notebook easier to write; I don't recommend doing that in your own analysis however) and check what's in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [Path('paddy-disease-classification/test_images'),Path('paddy-disease-classification/.DS_Store'),Path('paddy-disease-classification/train.csv'),Path('paddy-disease-classification/train_images'),Path('paddy-disease-classification/sample_submission.csv')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "set_seed(42)\n",
    "\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are in `train_images`, so let's grab a list of all of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_path = path/'train_images'\n",
    "files = get_image_files(trn_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and take a look at one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=96x128>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = PILImage.create(files[0])\n",
    "print(img.size)\n",
    "img.to_thumb(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the images might be 480x640 -- let's check all their sizes. This is faster if we do it in parallel, so we'll use fastcore's `parallel` for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640)    10403\n",
       "(640, 480)        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from fastcore.parallel import *\n",
    "\n",
    "def f(o): return PILImage.create(o).size\n",
    "sizes = parallel(f, files, n_workers=8)\n",
    "pd.Series(sizes).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're nearly all the same size, except for a few. Because of those few, however, we'll need to make sure we always resize each image to common dimensions first, otherwise fastai won't be able to create batches. For now, we'll just squish them to 480x480 images, and then once they're in batches we do a random resized crop down to a smaller size, along with the other default fastai augmentations provided by `aug_transforms`. We'll start out with small resized images, since we want to be able to iterate quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:1295: UserWarning: The operator 'aten::_linalg_solve_ex.result' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not do one pass in your dataloader, there is something wrong in it. Please see the stack trace below:\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Adaptive pool MPS: input sizes must be divisible by output sizes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dls \u001b[38;5;241m=\u001b[39m \u001b[43mImageDataLoaders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrn_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_pct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mitem_tfms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mResize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m480\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msquish\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_tfms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maug_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m dls\u001b[38;5;241m.\u001b[39mshow_batch(max_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastai/vision/data.py:123\u001b[0m, in \u001b[0;36mImageDataLoaders.from_folder\u001b[0;34m(cls, path, train, valid, valid_pct, seed, vocab, item_tfms, batch_tfms, img_cls, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m get_items \u001b[38;5;241m=\u001b[39m get_image_files \u001b[38;5;28;01mif\u001b[39;00m valid_pct \u001b[38;5;28;01melse\u001b[39;00m partial(get_image_files, folders\u001b[38;5;241m=\u001b[39m[train, valid])\n\u001b[1;32m    117\u001b[0m dblock \u001b[38;5;241m=\u001b[39m DataBlock(blocks\u001b[38;5;241m=\u001b[39m(ImageBlock(img_cls), CategoryBlock(vocab\u001b[38;5;241m=\u001b[39mvocab)),\n\u001b[1;32m    118\u001b[0m                    get_items\u001b[38;5;241m=\u001b[39mget_items,\n\u001b[1;32m    119\u001b[0m                    splitter\u001b[38;5;241m=\u001b[39msplitter,\n\u001b[1;32m    120\u001b[0m                    get_y\u001b[38;5;241m=\u001b[39mparent_label,\n\u001b[1;32m    121\u001b[0m                    item_tfms\u001b[38;5;241m=\u001b[39mitem_tfms,\n\u001b[1;32m    122\u001b[0m                    batch_tfms\u001b[38;5;241m=\u001b[39mbatch_tfms)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastai/data/core.py:284\u001b[0m, in \u001b[0;36mDataLoaders.from_dblock\u001b[0;34m(cls, dblock, source, path, bs, val_bs, shuffle, device, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_dblock\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \n\u001b[1;32m    275\u001b[0m     dblock, \u001b[38;5;66;03m# `DataBlock` object\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    283\u001b[0m ):\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_bs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_bs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastai/data/block.py:157\u001b[0m, in \u001b[0;36mDataBlock.dataloaders\u001b[0;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m dsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets(source, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    156\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: verbose}\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdsets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mafter_item\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_tfms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mafter_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_tfms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastai/data/core.py:337\u001b[0m, in \u001b[0;36mFilteredBase.dataloaders\u001b[0;34m(self, bs, shuffle_train, shuffle, val_shuffle, n, path, dl_type, dl_kwargs, device, drop_last, val_bs, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dl \u001b[38;5;241m=\u001b[39m dl_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    336\u001b[0m def_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbs\u001b[39m\u001b[38;5;124m'\u001b[39m:bs \u001b[38;5;28;01mif\u001b[39;00m val_bs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m val_bs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m'\u001b[39m:val_shuffle,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[0;32m--> 337\u001b[0m dls \u001b[38;5;241m=\u001b[39m [dl] \u001b[38;5;241m+\u001b[39m [dl\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(i), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))\n\u001b[1;32m    338\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_subsets)]\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbunch_type(\u001b[38;5;241m*\u001b[39mdls, path\u001b[38;5;241m=\u001b[39mpath, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastai/data/core.py:337\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    335\u001b[0m dl \u001b[38;5;241m=\u001b[39m dl_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    336\u001b[0m def_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbs\u001b[39m\u001b[38;5;124m'\u001b[39m:bs \u001b[38;5;28;01mif\u001b[39;00m val_bs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m val_bs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m'\u001b[39m:val_shuffle,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[0;32m--> 337\u001b[0m dls \u001b[38;5;241m=\u001b[39m [dl] \u001b[38;5;241m+\u001b[39m [\u001b[43mdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdef_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdl_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_subsets)]\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbunch_type(\u001b[38;5;241m*\u001b[39mdls, path\u001b[38;5;241m=\u001b[39mpath, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastai/data/core.py:97\u001b[0m, in \u001b[0;36mTfmdDL.new\u001b[0;34m(self, dataset, cls, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_n_inp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_types\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m         res\u001b[38;5;241m.\u001b[39m_n_inp,res\u001b[38;5;241m.\u001b[39m_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_inp,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_types\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastai/data/core.py:80\u001b[0m, in \u001b[0;36mTfmdDL._one_pass\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_batch([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_item(\u001b[38;5;28;01mNone\u001b[39;00m)])\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: b \u001b[38;5;241m=\u001b[39m to_device(b, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 80\u001b[0m its \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(its, (\u001b[38;5;28mlist\u001b[39m,\u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(its)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(its)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_types \u001b[38;5;241m=\u001b[39m explode_types(its)\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastcore/transform.py:208\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, o)\u001b[0m\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, o): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompose_tfms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastcore/transform.py:158\u001b[0m, in \u001b[0;36mcompose_tfms\u001b[0;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tfms:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_enc: f \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mdecode\n\u001b[0;32m--> 158\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastai/vision/augment.py:49\u001b[0m, in \u001b[0;36mRandTransform.__call__\u001b[0;34m(self, b, split_idx, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     44\u001b[0m     b, \n\u001b[1;32m     45\u001b[0m     split_idx:\u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# Index of the train/valid dataset\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     47\u001b[0m ):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_call(b, split_idx\u001b[38;5;241m=\u001b[39msplit_idx)\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo \u001b[38;5;28;01melse\u001b[39;00m b\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastcore/transform.py:81\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencodes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastcore/transform.py:91\u001b[0m, in \u001b[0;36mTransform._call\u001b[0;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, x, split_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m split_idx\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastcore/transform.py:98\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[0;32m---> 98\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastcore/transform.py:98\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     96\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[0;32m---> 98\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastcore/transform.py:97\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     96\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, x, ret)\n\u001b[1;32m     98\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastcore/dispatch.py:120\u001b[0m, in \u001b[0;36mTypeDispatch.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastai/vision/augment.py:546\u001b[0m, in \u001b[0;36mRandomResizedCropGPU.encodes\u001b[0;34m(self, x)\u001b[0m\n\u001b[0;32m--> 546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencodes\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:TensorImage\u001b[38;5;241m|\u001b[39mTensorPoint\u001b[38;5;241m|\u001b[39mTensorBBox): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastai/vision/augment.py:544\u001b[0m, in \u001b[0;36mRandomResizedCropGPU._encode\u001b[0;34m(self, x, mode)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mode):\n\u001b[1;32m    543\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtl[\u001b[38;5;241m0\u001b[39m]:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtl[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcp_size[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtl[\u001b[38;5;241m1\u001b[39m]:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtl[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcp_size[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m--> 544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine_coord\u001b[49m\u001b[43m(\u001b[49m\u001b[43msz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastai/vision/augment.py:391\u001b[0m, in \u001b[0;36maffine_coord\u001b[0;34m(x, mat, coord_tfm, sz, mode, pad_mode, align_corners)\u001b[0m\n\u001b[1;32m    389\u001b[0m coords \u001b[38;5;241m=\u001b[39m affine_grid(mat, x\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m size, align_corners\u001b[38;5;241m=\u001b[39malign_corners)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coord_tfm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: coords \u001b[38;5;241m=\u001b[39m coord_tfm(coords)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TensorImage(\u001b[43m_grid_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_corners\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastai/vision/augment.py:363\u001b[0m, in \u001b[0;36m_grid_sample\u001b[0;34m(x, coords, mode, padding_mode, align_corners)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# If we're resizing up by >200%, and we're zooming less than that, interpolate first\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m d\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m d\u001b[38;5;241m>\u001b[39mz:\n\u001b[0;32m--> 363\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marea\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecompute_scale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mgrid_sample(x, coords, mode\u001b[38;5;241m=\u001b[39mmode, padding_mode\u001b[38;5;241m=\u001b[39mpadding_mode, align_corners\u001b[38;5;241m=\u001b[39malign_corners)\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:3834\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3773\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Down/up samples the input to either the given :attr:`size` or the given\u001b[39;00m\n\u001b[1;32m   3774\u001b[0m \u001b[38;5;124;03m:attr:`scale_factor`\u001b[39;00m\n\u001b[1;32m   3775\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3831\u001b[0m \u001b[38;5;124;03m    {backward_reproducibility_note}\u001b[39;00m\n\u001b[1;32m   3832\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m-> 3834\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3835\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3836\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3837\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3838\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3841\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecompute_scale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecompute_scale_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mantialias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mantialias\u001b[49m\n\u001b[1;32m   3844\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marea\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest-exact\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   3847\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m align_corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/torch/overrides.py:1551\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1545\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1546\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1547\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1550\u001b[0m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1551\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/fastai/torch_core.py:382\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 382\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/torch/_tensor.py:1295\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1295\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:3947\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marea\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3946\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m output_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43madaptive_avg_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marea\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3949\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m output_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/TAPPS/DS_APPS/anaconda3/envs/tensorflow/lib/python3.9/site-packages/torch/nn/functional.py:1214\u001b[0m, in \u001b[0;36madaptive_avg_pool2d\u001b[0;34m(input, output_size)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(adaptive_avg_pool2d, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, output_size)\n\u001b[1;32m   1213\u001b[0m _output_size \u001b[38;5;241m=\u001b[39m _list_with_default(output_size, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 1214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madaptive_avg_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_output_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Adaptive pool MPS: input sizes must be divisible by output sizes."
     ]
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, seed=42,\n",
    "    item_tfms=Resize(480, method='squish'),\n",
    "    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n",
    "\n",
    "dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a model. To pick an architecture, we should look at the options in [The best vision models for fine-tuning](https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning). I like the looks of `resnet26d`, which is the fastest resolution-independent model which gets into the top-15 lists there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, 'resnet26d', metrics=error_rate, path='.').to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the learning rate finder shows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(suggest_funcs=(valley, slide))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lr_find` generally recommends rather conservative learning rates, to ensure that your model will train successfully. I generally like to push it a bit higher if I can. Let's train a few epochs and see how it looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(3, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to build our first submission. Let's take a look at the sample Kaggle provided to see what it needs to look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv(path/'sample_submission.csv')\n",
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so we need a CSV containing all the test images, in alphabetical order, and the predicted label for each one. We can create the needed test set using fastai like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_files = get_image_files(path/'test_images').sorted()\n",
    "tst_dl = dls.test_dl(tst_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get the probabilities of each class, and the index of the most likely class, from this test set (the 2nd thing returned by `get_preds` are the targets, which are blank for a test set, so we discard them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs,_,idxs = learn.get_preds(dl=tst_dl, with_decoded=True)\n",
    "idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These need to be mapped to the names of each of these diseases, these names are stored by fastai automatically in the `vocab`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create an apply this mapping using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(enumerate(dls.vocab))\n",
    "results = pd.Series(idxs.numpy(), name=\"idxs\").map(mapping)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle expects the submission as a CSV file, so let's save it, and check the first few lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss['label'] = results\n",
    "ss.to_csv('subm.csv', index=False)\n",
    "!head subm.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's submit this to kaggle. We can do it from the notebook if we're running on Kaggle, otherwise we can use the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not iskaggle:\n",
    "    from kaggle import api\n",
    "    api.competition_submit_cli('subm.csv', 'initial rn26d 128px', comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! We successfully created a submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial submission is not very good (top 80% of teams) but it only took a minute to train. The important thing is that we have a good starting point to iterate from, and we can do rapid iterations. Every step from loading the data to creating the model to submitting to Kaggle is all automated and runs quickly.\n",
    "\n",
    "Therefore, we can now try lots of things quickly and easily and use those experiments to improve our results. In the next notebook, we'll do exactly that! So if you're ready, take a look at [part 2 of the series](https://www.kaggle.com/code/jhoward/small-models-road-to-the-top-part-2/).\n",
    "\n",
    "If you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. And if you have any questions or comments, please pop them below -- I read every comment I receive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addendum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fastkaggle` also provides a function that pushes a notebook to Kaggle Notebooks. I wrote this notebook on my own machine, and pushed it to Kaggle from there -- here's the command I used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not iskaggle:\n",
    "    push_notebook('jhoward', 'first-steps-road-to-the-top-part-1',\n",
    "                  title='First Steps: Road to the Top, Part 1',\n",
    "                  file='first-steps-road-to-the-top-part-1.ipynb',\n",
    "                  competition=comp, private=False, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
